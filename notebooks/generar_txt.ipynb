{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 64, 128]) torch.Size([32, 3])\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "from datasets import KusisqaDim\n",
    "from datasets.utils import randomcrop, centercrop\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# dataset_train = KusisqaDim(\n",
    "#     \"../ser_datasets/test_kusisqa/audio-alegre.csv\",\n",
    "#     \"../ser_datasets/test_kusisqa/Audio-Alegre/\",\n",
    "#     transform=[centercrop],\n",
    "# )\n",
    "\n",
    "dataset_train = KusisqaDim(\n",
    "    \"../ser_datasets/test_kusisqa/audio-alegre.csv\",\n",
    "    \"../ser_datasets/test_kusisqa/Audio-Alegre/\",\n",
    "    transform=[centercrop],\n",
    ")\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    dataset_train,\n",
    "    batch_size=32,\n",
    "    shuffle=False,\n",
    "    num_workers=3,\n",
    "    persistent_workers=True,\n",
    ")\n",
    "\n",
    "for x,y in train_dataloader:\n",
    "    print(x.shape, y.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/luisbch/.local/lib/python3.8/site-packages/torch/nn/modules/lazy.py:178: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2.9579, 2.1445, 3.9237]) tensor([5., 4., 5.])\n",
      "tensor([2.8535, 2.3622, 3.6735]) tensor([5., 4., 5.])\n",
      "tensor([2.4372, 1.7594, 2.9781]) tensor([5., 4., 5.])\n",
      "tensor([2.5489, 2.0620, 3.4217]) tensor([5., 4., 5.])\n",
      "tensor([2.4598, 2.2247, 2.8442]) tensor([5., 4., 5.])\n",
      "tensor([2.1250, 1.4912, 2.8644]) tensor([4., 2., 5.])\n",
      "tensor([2.2166, 1.7539, 2.9273]) tensor([4., 2., 5.])\n",
      "tensor([2.1129, 1.7675, 2.8982]) tensor([4., 2., 5.])\n",
      "tensor([2.6462, 2.5861, 3.1654]) tensor([5., 4., 5.])\n",
      "tensor([1.7023, 1.5733, 2.4109]) tensor([5., 4., 4.])\n",
      "tensor([2.6735, 2.7285, 3.0088]) tensor([5., 4., 5.])\n",
      "tensor([2.5481, 3.0122, 2.9603]) tensor([5., 4., 5.])\n",
      "tensor([2.8977, 2.6400, 3.0697]) tensor([5., 4., 5.])\n",
      "tensor([2.0736, 2.0252, 2.6347]) tensor([4., 2., 4.])\n",
      "tensor([2.6673, 4.5948, 2.8334]) tensor([5., 4., 5.])\n",
      "tensor([1.1296, 2.0319, 2.0217]) tensor([3., 2., 4.])\n",
      "tensor([2.0766, 1.3705, 2.8005]) tensor([4., 2., 4.])\n",
      "tensor([1.7805, 1.3918, 2.3369]) tensor([2., 2., 4.])\n",
      "tensor([2.0068, 1.5052, 2.1427]) tensor([2., 2., 4.])\n",
      "tensor([1.7355, 1.3850, 1.9359]) tensor([2., 2., 4.])\n",
      "tensor([1.7092, 1.7350, 2.1449]) tensor([4., 2., 5.])\n",
      "tensor([2.0653, 1.6461, 2.8914]) tensor([3., 2., 5.])\n",
      "tensor([2.2548, 1.9183, 2.7477]) tensor([3., 2., 5.])\n",
      "tensor([2.7220, 1.7847, 3.1964]) tensor([3., 2., 5.])\n",
      "tensor([2.9219, 1.8880, 3.3951]) tensor([4., 2., 5.])\n",
      "tensor([2.4667, 2.0475, 2.8644]) tensor([5., 4., 5.])\n",
      "tensor([2.8300, 2.1430, 3.7589]) tensor([5., 4., 5.])\n",
      "tensor([2.8924, 2.0812, 3.5910]) tensor([5., 4., 5.])\n",
      "tensor([1.9853, 1.7093, 2.5973]) tensor([4., 2., 5.])\n",
      "tensor([3.2366, 2.4852, 3.5642]) tensor([4., 2., 5.])\n",
      "tensor([1.2876, 1.8845, 2.1991]) tensor([5., 4., 5.])\n",
      "tensor([2.4664, 2.1850, 2.9753]) tensor([3., 2., 5.])\n",
      "tensor([2.9123, 2.8628, 3.8808]) tensor([4., 2., 5.])\n",
      "tensor([1.9457, 1.5438, 2.4617]) tensor([4., 2., 5.])\n",
      "tensor([1.6815, 2.2429, 2.4255]) tensor([3., 2., 5.])\n",
      "tensor([1.7662, 1.9778, 2.2722]) tensor([4., 2., 5.])\n",
      "tensor([1.7510, 1.7946, 2.5969]) tensor([4., 2., 5.])\n",
      "tensor([1.6508, 1.5368, 1.8850]) tensor([4., 2., 5.])\n",
      "tensor([2.5607, 2.3846, 3.0857]) tensor([4., 2., 5.])\n",
      "tensor([2.2060, 1.9235, 3.0482]) tensor([4., 2., 5.])\n",
      "tensor([2.8809, 2.4717, 3.4061]) tensor([4., 2., 5.])\n",
      "tensor([2.7255, 2.1013, 3.1510]) tensor([5., 4., 5.])\n",
      "tensor([2.3483, 2.9038, 2.3021]) tensor([4., 4., 5.])\n",
      "tensor([2.6724, 2.2529, 2.8165]) tensor([4., 2., 5.])\n",
      "tensor([2.7293, 2.6711, 3.1142]) tensor([5., 4., 5.])\n",
      "tensor([2.2750, 1.7603, 2.7446]) tensor([4., 4., 5.])\n",
      "tensor([2.8094, 2.6368, 2.7515]) tensor([4., 2., 5.])\n",
      "tensor([3.1515, 2.6578, 3.2388]) tensor([4., 2., 5.])\n",
      "tensor([1.6745, 1.4199, 2.1014]) tensor([4., 2., 5.])\n",
      "tensor([4.1333, 3.6730, 3.8102]) tensor([5., 4., 5.])\n",
      "tensor([3.5587, 3.1777, 3.5041]) tensor([5., 4., 5.])\n",
      "tensor([3.1731, 4.6029, 3.1975]) tensor([5., 4., 5.])\n",
      "tensor([3.9943, 2.7403, 4.1688]) tensor([5., 4., 5.])\n",
      "tensor([2.9169, 2.8575, 3.2288]) tensor([4., 2., 5.])\n",
      "tensor([3.1421, 2.5104, 3.6855]) tensor([4., 2., 5.])\n",
      "tensor([3.5776, 2.1713, 3.7198]) tensor([5., 2., 5.])\n",
      "tensor([3.1799, 2.7224, 3.2378]) tensor([5., 2., 5.])\n",
      "tensor([3.5266, 2.1553, 3.8471]) tensor([5., 4., 5.])\n",
      "tensor([3.1414, 2.1855, 3.2854]) tensor([4., 2., 5.])\n",
      "tensor([2.9905, 2.1200, 3.0904]) tensor([4., 2., 5.])\n",
      "tensor([2.9300, 2.5678, 3.3094]) tensor([2., 4., 5.])\n",
      "tensor([2.5620, 1.7542, 2.6730]) tensor([4., 2., 5.])\n"
     ]
    }
   ],
   "source": [
    "from models.cnn_dim import CNNDim\n",
    "\n",
    "model = CNNDim.load_from_checkpoint(\"../logs/kusisqa_ccc/dot8kgqa/checkpoints/epoch=9-step=479.ckpt\",lr=0.001)\n",
    "\n",
    "# print(model.learning_rate)\n",
    "# prints the learning_rate you used in this checkpoint\n",
    "\n",
    "model.eval()\n",
    "\n",
    "for x,y in train_dataloader:\n",
    "  resultado = model(x)\n",
    "  for i in range(len(resultado)):\n",
    "    print(resultado[i].data, y[i])\n",
    "  \n",
    "  break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on batch: 0.9122545123100281\n",
      "Accuracy on batch: 0.8550463318824768\n",
      "Accuracy on all data: 0.8845731616020203\n"
     ]
    }
   ],
   "source": [
    "path_pesos = \"../logs/kusisqa_ccc/2rrt54ay/checkpoints/epoch=63-step=3071.ckpt\"\n",
    "from models.cnn_dim import CNNDim\n",
    "from models.metrics import CCC\n",
    "\n",
    "model = CNNDim.load_from_checkpoint(path_pesos,lr=0.001)\n",
    "model.eval()\n",
    "\n",
    "from torchmetrics import MeanAbsoluteError\n",
    "metric = MeanAbsoluteError()\n",
    "for x,y in train_dataloader:\n",
    "  resultado = model(x)\n",
    "  acc = metric(resultado, y)\n",
    "  print(f\"Accuracy on batch: { acc}\")\n",
    "  \n",
    "acc = metric.compute()\n",
    "print(f\"Accuracy on all data: {acc}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRISTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 64, 128]) torch.Size([32, 3])\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'MeanAbsoluteError' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-ea5dad0db6c0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0mmetric\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMeanAbsoluteError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m   \u001b[0mresultado\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'MeanAbsoluteError' is not defined"
     ]
    }
   ],
   "source": [
    "dataset_train = KusisqaDim(\n",
    "    \"../ser_datasets/test_kusisqa/audio-triste.csv\",\n",
    "    \"../ser_datasets/test_kusisqa/Audio-Triste/\",\n",
    "    transform=[centercrop],\n",
    ")\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    dataset_train,\n",
    "    batch_size=32,\n",
    "    shuffle=False,\n",
    "    num_workers=3,\n",
    "    persistent_workers=True,\n",
    ")\n",
    "\n",
    "for x,y in train_dataloader:\n",
    "    print(x.shape, y.shape)\n",
    "    break\n",
    "\n",
    "path_pesos = \"../checkpoints/epoch=222-step=5351.ckpt\"\n",
    "from models.cnn_dim import CNNDim\n",
    "from models.metrics import CCC\n",
    "\n",
    "model = CNNDim.load_from_checkpoint(path_pesos,lr=0.001)\n",
    "model.eval()\n",
    "\n",
    "metric = MeanAbsoluteError()\n",
    "for x,y in train_dataloader:\n",
    "  resultado = model(x)\n",
    "  acc = metric(resultado, y)\n",
    "  for i in range(len(resultado)):\n",
    "    print(resultado[i].data, y[i])\n",
    "  print(f\"MAE batch: { acc}\")\n",
    "  \n",
    "acc = metric.compute()\n",
    "print(f\"MAE: { acc}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alegre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 64, 128]) torch.Size([32, 3])\n",
      "tensor([3.2521, 2.6007, 4.4864]) tensor([5., 4., 5.])\n",
      "tensor([3.7965, 2.7649, 3.8055]) tensor([5., 4., 5.])\n",
      "tensor([4.1385, 2.7048, 4.0928]) tensor([5., 4., 5.])\n",
      "tensor([3.1979, 3.0571, 3.2159]) tensor([5., 4., 5.])\n",
      "tensor([3.6597, 2.9202, 3.9953]) tensor([5., 4., 5.])\n",
      "tensor([3.1832, 2.2277, 3.4002]) tensor([4., 2., 5.])\n",
      "tensor([2.6669, 1.9871, 3.2333]) tensor([4., 2., 5.])\n",
      "tensor([2.6341, 2.2736, 3.5712]) tensor([4., 2., 5.])\n",
      "tensor([3.0214, 2.5459, 3.0417]) tensor([5., 4., 5.])\n",
      "tensor([2.4021, 3.0157, 2.8730]) tensor([5., 4., 4.])\n",
      "tensor([3.7051, 2.7452, 3.6406]) tensor([5., 4., 5.])\n",
      "tensor([3.4122, 3.1411, 3.8151]) tensor([5., 4., 5.])\n",
      "tensor([4.8600, 3.0570, 4.7074]) tensor([5., 4., 5.])\n",
      "tensor([2.4780, 2.4321, 3.0252]) tensor([4., 2., 4.])\n",
      "tensor([3.7312, 3.8554, 3.5990]) tensor([5., 4., 5.])\n",
      "tensor([1.6940, 3.0005, 2.8840]) tensor([3., 2., 4.])\n",
      "tensor([2.4270, 1.9006, 3.1846]) tensor([4., 2., 4.])\n",
      "tensor([2.6434, 1.8302, 2.9024]) tensor([2., 2., 4.])\n",
      "tensor([2.5540, 2.0898, 2.7187]) tensor([2., 2., 4.])\n",
      "tensor([3.3926, 2.1953, 3.4430]) tensor([2., 2., 4.])\n",
      "tensor([2.7556, 2.3568, 3.4051]) tensor([4., 2., 5.])\n",
      "tensor([2.8136, 2.7081, 3.4099]) tensor([3., 2., 5.])\n",
      "tensor([3.0567, 2.7076, 3.2360]) tensor([3., 2., 5.])\n",
      "tensor([3.5192, 2.6497, 3.6833]) tensor([3., 2., 5.])\n",
      "tensor([3.5818, 2.1237, 3.8267]) tensor([4., 2., 5.])\n",
      "tensor([2.8243, 2.9009, 2.9231]) tensor([5., 4., 5.])\n",
      "tensor([3.8480, 2.6029, 3.6887]) tensor([5., 4., 5.])\n",
      "tensor([3.4822, 2.6219, 3.2372]) tensor([5., 4., 5.])\n",
      "tensor([2.4200, 2.1097, 2.8679]) tensor([4., 2., 5.])\n",
      "tensor([3.9042, 3.0862, 3.9829]) tensor([4., 2., 5.])\n",
      "tensor([1.2887, 2.8462, 2.3560]) tensor([5., 4., 5.])\n",
      "tensor([2.7782, 3.0801, 3.8675]) tensor([3., 2., 5.])\n",
      "MAE batch: 1.104507565498352\n",
      "tensor([3.1093, 2.8336, 4.8602]) tensor([4., 2., 5.])\n",
      "tensor([2.3233, 2.3515, 2.9185]) tensor([4., 2., 5.])\n",
      "tensor([2.2960, 2.6261, 3.0747]) tensor([3., 2., 5.])\n",
      "tensor([2.1383, 2.4402, 2.6916]) tensor([4., 2., 5.])\n",
      "tensor([2.8137, 2.2381, 3.4401]) tensor([4., 2., 5.])\n",
      "tensor([2.3541, 2.3519, 2.7629]) tensor([4., 2., 5.])\n",
      "tensor([3.8080, 2.7313, 3.7140]) tensor([4., 2., 5.])\n",
      "tensor([2.8350, 1.7357, 3.0561]) tensor([4., 2., 5.])\n",
      "tensor([3.7569, 3.1171, 4.6115]) tensor([4., 2., 5.])\n",
      "tensor([3.2963, 2.5996, 3.9284]) tensor([5., 4., 5.])\n",
      "tensor([2.1178, 3.6686, 2.4068]) tensor([4., 4., 5.])\n",
      "tensor([3.6256, 2.6249, 3.7538]) tensor([4., 2., 5.])\n",
      "tensor([3.3236, 3.3422, 4.3013]) tensor([5., 4., 5.])\n",
      "tensor([2.7241, 2.7186, 3.0310]) tensor([4., 4., 5.])\n",
      "tensor([3.9289, 3.3361, 3.7072]) tensor([4., 2., 5.])\n",
      "tensor([3.6158, 3.6851, 3.2189]) tensor([4., 2., 5.])\n",
      "tensor([2.8490, 2.0124, 3.6995]) tensor([4., 2., 5.])\n",
      "tensor([4.8471, 4.2416, 3.9190]) tensor([5., 4., 5.])\n",
      "tensor([4.0701, 3.2440, 4.2984]) tensor([5., 4., 5.])\n",
      "tensor([4.9429, 4.5992, 3.8469]) tensor([5., 4., 5.])\n",
      "tensor([4.4992, 2.9464, 3.9643]) tensor([5., 4., 5.])\n",
      "tensor([3.5059, 3.2532, 4.1613]) tensor([4., 2., 5.])\n",
      "tensor([3.6043, 2.6847, 3.6711]) tensor([4., 2., 5.])\n",
      "tensor([3.9665, 2.6168, 3.7656]) tensor([5., 2., 5.])\n",
      "tensor([3.7672, 3.3875, 4.1195]) tensor([5., 2., 5.])\n",
      "tensor([4.1254, 3.1320, 4.4712]) tensor([5., 4., 5.])\n",
      "tensor([3.6270, 2.6869, 3.6203]) tensor([4., 2., 5.])\n",
      "tensor([3.8798, 3.0702, 3.8144]) tensor([4., 2., 5.])\n",
      "tensor([3.6204, 3.2483, 3.4918]) tensor([2., 4., 5.])\n",
      "tensor([4.0944, 2.2945, 3.7599]) tensor([4., 2., 5.])\n",
      "MAE batch: 0.9825714230537415\n",
      "MAE: 1.045506238937378\n"
     ]
    }
   ],
   "source": [
    "dataset_train = KusisqaDim(\n",
    "    \"../ser_datasets/test_kusisqa/audio-alegre.csv\",\n",
    "    \"../ser_datasets/test_kusisqa/Audio-Alegre/\",\n",
    "    transform=[centercrop],\n",
    ")\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    dataset_train,\n",
    "    batch_size=32,\n",
    "    shuffle=False,\n",
    "    num_workers=3,\n",
    "    persistent_workers=True,\n",
    ")\n",
    "\n",
    "for x,y in train_dataloader:\n",
    "    print(x.shape, y.shape)\n",
    "    break\n",
    "\n",
    "path_pesos = \"../logs/kusisqa_ccc/2rrt54ay/checkpoints/epoch=63-step=3071.ckpt\"\n",
    "from models.cnn_dim import CNNDim\n",
    "from models.metrics import CCC\n",
    "\n",
    "model = CNNDim.load_from_checkpoint(path_pesos,lr=0.001)\n",
    "model.eval()\n",
    "\n",
    "metric = MeanAbsoluteError()\n",
    "for x,y in train_dataloader:\n",
    "  resultado = model(x)\n",
    "  acc = metric(resultado, y)\n",
    "  for i in range(len(resultado)):\n",
    "    print(resultado[i].data, y[i])\n",
    "  print(f\"MAE batch: { acc}\")\n",
    "  \n",
    "acc = metric.compute()\n",
    "print(f\"MAE: { acc}\")\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
